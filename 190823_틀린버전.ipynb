{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#이미지가 저장된 디렉토리 불러오기\n",
    "data_dir = '/Users/joannakang/Desktop/kakaoclassification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apeach', 'Muzi_con', 'Jay']\n"
     ]
    }
   ],
   "source": [
    "class_name = os.listdir(data_dir)\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(class_name)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-d7f6be2a4897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "for i in range(len(class_name)):\n",
    "    path = os.path.join(data_dir, class_name[i])\n",
    "    img_list = os.listdir(path)\n",
    "    for j in img_list:\n",
    "        img = os.path.join(path, j)\n",
    "        img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (28, 28), interpolation = cv2.INTER_CUBIC)\n",
    "        img = img.reshape((28, 28, 1))\n",
    "        train_input.append(img)\n",
    "        train_label.append(onehot_encoded[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "print(len((train_input)))\n",
    "print(len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 28, 28, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = np.array(train_input)\n",
    "train_label = np.array(train_label)\n",
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = train_input[1].reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a25bdebe0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeC+j89Cdj9sLECFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a24ae0be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 28, 28, 1)\n",
      "(71, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(train_label.shape[1], activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 19,395\n",
      "Trainable params: 19,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input arrays should have the same number of samples as target arrays. Found 76 input samples and 71 target samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-6695d704973c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    802\u001b[0m             ]\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0mcheck_array_length_consistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0;31m# Additional checks to avoid users mistakenly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_array_length_consistency\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    235\u001b[0m                          \u001b[0;34m'the same number of samples as target arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                          \u001b[0;34m'Found '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input samples '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         raise ValueError('All sample_weight arrays should have '\n",
      "\u001b[0;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 76 input samples and 71 target samples."
     ]
    }
   ],
   "source": [
    "model.fit(x = train_input, y = train_label, batch_size = 5, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
