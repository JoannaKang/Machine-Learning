{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#이미지가 저장된 디렉토리 불러오기\n",
    "data_dir = '/Users/joannakang/Desktop/kakaoclassification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apeach', 'Muzi_con', 'Jay']\n"
     ]
    }
   ],
   "source": [
    "#os.listdir = 경로 내의 파일명을 리스트화 시킨다\n",
    "#ds.store 파일 생겼을때 : sudo find / -name \".DS_Store\" -depth -exec rm {} \\;\n",
    "class_name = os.listdir(data_dir)\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(class_name)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_name 의 리스트 갯수만큼 for문을 반복\n",
    "#class_name 리스트에 있는 이름 순서대로 Index에 이름이 들어가면서 for문이 실행됨\n",
    "for index in range(len(class_name)):\n",
    "    path = os.path.join(data_dir, class_name[index])\n",
    "    img_list = os.listdir(path)\n",
    "    for j in img_list:\n",
    "        img = os.path.join(path, j)\n",
    "        img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (28, 28), interpolation = cv2.INTER_CUBIC)\n",
    "        img = img.reshape((28, 28, 1))\n",
    "        train_input.append(img)\n",
    "        train_label.append(onehot_encoded[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apeach\n",
      "/Users/joannakang/Desktop/kakaoclassification/Apeach\n"
     ]
    }
   ],
   "source": [
    "list(range(len(class_name)))\n",
    "print(class_name[0])\n",
    "print(os.path.join(data_dir,class_name[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "print(len((train_input)))\n",
    "print(len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 28, 28, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = np.array(train_input)\n",
    "train_label = np.array(train_label)\n",
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = train_input[1].reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a282a9630>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngaD+H3ny+kqr/nIoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a28242b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 28, 28, 1)\n",
      "(71, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#모델을 구성한다\n",
    "model = Sequential()\n",
    "#보통 2의 배수로 숫자 지정 /램 사양에 맞춰서 지정해야함\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2, 2))) #불필요한 빈공간을 지운다\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(train_label.shape[1], activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 19,395\n",
      "Trainable params: 19,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#binary crossentropy 어려운내용....\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6629 - acc: 0.6667\n",
      "Epoch 2/5\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6341 - acc: 0.6620\n",
      "Epoch 3/5\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6322 - acc: 0.7606\n",
      "Epoch 4/5\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.5516 - acc: 0.7700\n",
      "Epoch 5/5\n",
      "71/71 [==============================] - 0s 990us/step - loss: 0.4788 - acc: 0.8357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a28bb70f0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch size = 학습시키는 데이터의 수 #epochs = 학습의 횟수\n",
    "model.fit(x = train_input, y = train_label, batch_size = 5, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 420us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46663058643609706, 0.8215962388146092]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정확도 / loss\n",
    "model.evaluate(x = train_input, y = train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
